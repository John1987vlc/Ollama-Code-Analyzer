# Ollama Code Analyzer ğŸš€  
**Your Private, Offline-First AI Co-pilot for Visual Studio Code**  

[![License: CC0-1.0](https://img.shields.io/badge/License-CC0%201.0-lightgrey.svg)](LICENSE)  
![VS Code](https://img.shields.io/badge/VS%20Code-Extension-blue)  
![Offline](https://img.shields.io/badge/Offline-Yes-green)  
![Privacy](https://img.shields.io/badge/Privacy-100%25-orange)  

<img src="./images/icon.png" alt="Logo" width="200">

Run AI-powered code analysis directly inside your editor â€” **fully offline, private, and secure**.  
Ollama Code Analyzer uses on-device AI models (like `gemma3n`) via [Ollama](https://ollama.com/) to help you:  

- ğŸ” Analyze code quality and detect subtle bugs  
- â™»ï¸ Refactor intelligently  
- ğŸ“ Generate functions from comments  
- ğŸ§ª Create unit tests automatically  
- ğŸ“š Explain complex code in seconds  
- ğŸ“Š Visualize your project with UML diagrams  

---

## ğŸ“‘ Table of Contents
- [âœ¨ Why Ollama Code Analyzer?](#-why-ollama-code-analyzer)
- [ğŸ“¦ Quick Setup](#-quick-setup)
- [ğŸ’» Core Commands](#-core-commands)
- [âš™ï¸ Configuration](#ï¸-configuration)
- [ğŸ“¸ Screenshots & Demo](#-screenshots--demo)
- [ğŸ›  Troubleshooting](#-troubleshooting)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“œ License](#-license)

---

## âœ¨ Why Ollama Code Analyzer?
In todayâ€™s development landscape, AI assistants are becoming indispensable â€” but most require sending your code to the cloud.  
With **Ollama Code Analyzer**, you get the **power of AI with complete privacy**:

- ğŸ›¡ **Private by Design** â€“ Runs entirely on your machine. No cloud. No leaks.  
- ğŸ“¶ **Offline-First** â€“ Works without internet. Ideal for remote work or travel.  
- ğŸ **Deep Bug Detection** â€“ Finds subtle logic errors missed by traditional linters.  
- âš¡ **Code Generation from Comments** â€“ Write `///` or `#` followed by your intent â€” AI writes the function.  
- ğŸ”„ **Context-Aware Refactoring** â€“ Improves performance, readability, and maintainability.  
- ğŸ“š **Instant Code Explanation** â€“ Understand unfamiliar code instantly.  
- ğŸ§ª **Automated Unit Test Creation** â€“ Uses frameworks like Jest or pytest.  
- ğŸ—º **UML Visualization** â€“ Generates PlantUML diagrams for your whole project.  

---

## ğŸ“¦ Quick Setup

### 1ï¸âƒ£ Install Graphviz (for UML Diagrams)
To generate UML diagrams, the extension uses PlantUML, which requires Graphviz to be installed on your system.

**Windows (using Chocolatey):**
```bash
choco install graphviz
```

**Linux (Debian/Ubuntu):**
```bash
_sudo apt-get install graphviz
```

**macOS (using Homebrew):**
```bash
brew install graphviz
```

### 2ï¸âƒ£ Install Ollama
Download from [ollama.com](https://ollama.com/download) for your OS.

### 3ï¸âƒ£ Download a Model
```bash
# Example: Pull the Gemma 7B model
ollama pull gemma3n:latest
```
> ğŸ’¡ You can also try `gemma3n:e2b` or other coding-optimized models.

### 3ï¸âƒ£ Install the Extension
```bash
# Install dependencies
npm install

# Package into a VSIX file
vsce package

# Install into VS Code
code --install-extension ollama-code-analyzer-*.vsix
```
Reload VS Code, and youâ€™re ready! ğŸ‰  

---

## ğŸ’» Core Commands
All commands are available via **Command Palette** (`Ctrl+Shift+P`) â†’ search **"Ollama Code Analyzer"** or right-click in the editor.

| Command                  | Description |
|--------------------------|-------------|
| **Smart Refactor**       | Refactor selected code intelligently. |
| **Explain Code**         | Explain the purpose & logic of code. |
| **Generate Unit Test**   | Create test files automatically. |
| **Analyze File/Project** | Deep static + AI-based analysis. |
| **Generate UML Diagram** | Create PlantUML architecture diagram. |

---

## âš™ï¸ Configuration
Settings in **VS Code â†’ Settings â†’ Extensions â†’ Ollama Code Analyzer**:

| Setting | Default | Description |
|---------|---------|-------------|
| `ollamaCodeAnalyzer.baseUrl` | `http://localhost:11434` | API endpoint for your local Ollama service. |
| `ollamaCodeAnalyzer.model` | `gemma3n:latest` | AI model to use (must be pulled via Ollama). |
| `ollamaCodeAnalyzer.outputLanguage` | `English` | Response language (`English` or `EspaÃ±ol`). |

---

## ğŸ“¸ Screenshots & Demo
---

---

## ğŸ›  Troubleshooting
- **Ollama service not running** â†’ Ensure you have started Ollama (`ollama serve`).  
- **Model not found** â†’ Pull the model before using: `ollama pull gemma3n:latest`.  
- **VSIX not installing** â†’ Make sure VS Code version supports local extensions.  

---

## ğŸ¤ Contributing
Contributions are welcome!  
1. Fork this repo  
2. Create a feature branch (`git checkout -b feature/my-feature`)  
3. Commit changes (`git commit -m "Add my feature"`)  
4. Push (`git push origin feature/my-feature`)  
5. Open a Pull Request  

---

## ğŸ“œ License
This project is licensed under **CC0 1.0 Universal** â€“ public domain dedication.  
See the [LICENSE](LICENSE) file for details.  